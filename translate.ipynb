{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90327956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class MiniLMEmbeddings(Embeddings):\n",
    "    def __init__(self):\n",
    "        self.model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    def embed_documents(self, texts: List[str], batch_size=500) -> List[List[float]]:\n",
    "        # Use batching to speed up the encoding\n",
    "        return self.model.encode(texts, batch_size=batch_size, show_progress_bar=True).tolist()\n",
    "\n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        return self.embed_documents([text])[0]\n",
    "\n",
    "data = pd.read_csv(\"train_data_v2_57k.csv\")\n",
    "#data, validation = train_test_split(data, test_size=250)\n",
    "validation = data.loc[val_indeces]\n",
    "data = data.drop(val_indeces)\n",
    "print(len(validation))\n",
    "print(len(data))\n",
    "\n",
    "# Filter only rows where 'en_title' is a string\n",
    "filtered_data = data[data['en_title'].apply(lambda x: isinstance(x, str))]\n",
    "\n",
    "# Vectorize the creation of Document objects\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=row['en_title'],\n",
    "        metadata={'en_title': row['en_title'], 'fr_title': row['fr_title']}\n",
    "    )\n",
    "    for _, row in filtered_data.iterrows()\n",
    "]\n",
    "\n",
    "vec_store = InMemoryVectorStore(MiniLMEmbeddings())\n",
    "vec_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adaedb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "api_key=os.environ[\"LITELLM_KEY\"]\n",
    "base_url=\"os.environ[\"LITELLM_IP\"]\"\n",
    "\n",
    "client = openai.OpenAI(\n",
    "    api_key=api_key,\n",
    "    base_url=base_url\n",
    ")\n",
    "\n",
    "def make_examples_section(docs):\n",
    "    lines = []\n",
    "    for doc in docs:\n",
    "        lines.append(f\"English: {doc.metadata['en_title']}\")\n",
    "        lines.append(f\"French: {doc.metadata['fr_title']}\\n\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def translate_with_few_shot(english_title, model=\"cheap-ian\", k_neighbors=5, verbose=False):\n",
    "    try:\n",
    "        system_prompt_template = (\"\"\"You are a highly skilled translator specializing in technical and legal documents, with specific expertise in translating English patent titles into the most accurate and natural French equivalents. Always maintain the precise technical terminology and meaning of the original, adapting phrasing for French patent standards. Return only the title/word translated, match the casing, do not be conversational. Here are some examples:\n",
    "                            \\n{examples}\"\"\")\n",
    "        prompt_template = ChatPromptTemplate.from_messages(\n",
    "            [(\"system\", system_prompt_template), (\"user\", \"{text}\")]\n",
    "        )\n",
    "        results = vec_store.similarity_search(query=english_title, k=k_neighbors)\n",
    "\n",
    "        prompt = prompt_template.invoke({\"examples\":make_examples_section(results), \"text\":english_title})\n",
    "        messages = prompt.to_messages()\n",
    "        sys_msg = messages[0].content\n",
    "        user_msg = messages[1].content\n",
    "\n",
    "        if verbose:\n",
    "            print(\"sys:\")\n",
    "            print(sys_msg)\n",
    "            print(\"user:\")\n",
    "            print(user_msg)\n",
    "\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": sys_msg\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": user_msg\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(english_title)\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "def translate_with_base_model(english_title, model=\"cheap-ian\"):\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages = [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a highly skilled translator specializing in technical and legal documents, with specific expertise in translating English patent titles into the most accurate and natural French equivalents. Always maintain the precise technical terminology and meaning of the original, adapting phrasing for French patent standards. Return only the title/word translated, match the casing, do not be conversational.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": english_title\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "        return response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(english_title)\n",
    "        print(e)\n",
    "        return \"\"\n",
    "\n",
    "#val_row = validation.iloc[-100]\n",
    "#print(\"Sample English: {} \\nSample French: {}\\n\".format(val_row[\"en_title\"], val_row[\"fr_title\"]))\n",
    "#translate_with_base_model(val_row[\"en_title\"])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5270a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "french_to_english = {\n",
    "    \"Bonjour\": \"Hello\",\n",
    "    \"Maison\": \"House\",\n",
    "    \"Chat\": \"Cat\",\n",
    "    \"Livre\": \"Book\",\n",
    "    \"Ã‰cole\": \"School\",\n",
    "    \"Pomme\": \"Apple\",\n",
    "    \"Chaise\": \"Chair\",\n",
    "    \"Amour\": \"Love\",\n",
    "    \"Eau\": \"Water\",\n",
    "    \"Nuit\": \"Night\"\n",
    "}\n",
    "\n",
    "for key, value in french_to_english.items():\n",
    "    translation = translate_with_base_model(value, model=\"best\")\n",
    "    print(f\"English: {value}, Translation: {translation}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f08b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "import sacrebleu\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "r_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "chrf = sacrebleu.CHRF()\n",
    "\n",
    "model = \"best\"\n",
    "validation[\"fr_translate_base\"] = validation[\"en_title\"].apply(lambda x: translate_with_base_model(x, model=model))\n",
    "validation[\"fr_translate_10-shot\"] = validation[\"en_title\"].apply(lambda x: translate_with_few_shot(x, model=model, k_neighbors=10))\n",
    "validation[\"fr_translate_5-shot\"] = validation[\"en_title\"].apply(lambda x: translate_with_few_shot(x, model=model, k_neighbors=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928f31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_output(input_text):\n",
    "    try:\n",
    "        text_without_asterisks = input_text.replace('**', '')\n",
    "        text_without_asterisks = text_without_asterisks.replace('\\n', '')\n",
    "        french_index = text_without_asterisks.find('French:')\n",
    "        if french_index != -1:\n",
    "            text_after_french = text_without_asterisks[french_index + len('French:'):]\n",
    "        else:\n",
    "            text_after_french = text_without_asterisks\n",
    "        french_index = text_without_asterisks.upper().find('French Translation:'.upper())\n",
    "        if french_index != -1:\n",
    "            text_after_french = text_after_french[french_index + len('French Translation:'):]\n",
    "        else:\n",
    "            text_after_french = text_after_french\n",
    "        final_text = text_after_french.upper()\n",
    "        return final_text\n",
    "    except:\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847b32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bert_score import score\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "import sacrebleu\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "validation = pd.read_csv('validation-titles.csv')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "r_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "chrf = sacrebleu.CHRF()\n",
    "\n",
    "def validation_score_generate(validation, model_column, ref_column=\"fr_title\", score_column=\"score\", clean_output = lambda x: x):\n",
    "    _, _, F1_base = score(validation[model_column].astype(str).apply(clean_output).tolist(), validation[ref_column].astype(str).tolist(), lang=\"fr\", device=device, batch_size=300, verbose=True)\n",
    "    c_scores_base = [chrf.sentence_score(translated, [ref]).score \n",
    "                 for translated, ref in zip(validation[model_column].astype(str).apply(clean_output), validation[ref_column].astype(str))]\n",
    "    rouge_scores_base = [r_scorer.score(ref, hyp)['rougeL'].fmeasure*100\n",
    "                     for ref, hyp in zip(validation[ref_column].astype(str), validation[model_column].astype(str).apply(clean_output))]\n",
    "    validation[score_column] = [(0.2*c + 0.3*f*100 + 0.5*r).item()\n",
    "                            for c, f, r in zip(c_scores_base, F1_base, rouge_scores_base)]\n",
    "    return validation\n",
    "\n",
    "def evaluate_translations_td_idf(df, model_column, ref_column=\"fr_title\", score_column=\"score\"):\n",
    "    # Concatenate reference and translated texts for vectorization\n",
    "    all_texts = df[ref_column].astype(str).tolist() + df[model_column].astype(str).tolist()\n",
    "    \n",
    "    # Create a TF-IDF Vectorizer\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Vectorize the texts\n",
    "    tfidf_matrix = vectorizer.fit_transform(all_texts)\n",
    "    \n",
    "    # Split the TF-IDF matrix into reference and model parts\n",
    "    ref_tfidf = tfidf_matrix[:len(df)]\n",
    "    model_tfidf = tfidf_matrix[len(df):]\n",
    "    \n",
    "    # Compute cosine similarity for each pair of reference/model texts\n",
    "    similarities = []\n",
    "    for ref_vec, model_vec in zip(ref_tfidf, model_tfidf):\n",
    "        similarity = cosine_similarity(ref_vec, model_vec)[0][0]\n",
    "        similarities.append(similarity)\n",
    "    \n",
    "    # Add similarity scores to the DataFrame\n",
    "    df[score_column] = similarities\n",
    "    return df\n",
    "\n",
    "validation = validation_score_generate(validation, model_column=\"fr_translate_base\", score_column=\"base_score\")\n",
    "validation = validation_score_generate(validation, model_column=\"fr_translate_5-shot\", score_column=\"5-shot-score\")\n",
    "validation = validation_score_generate(validation, model_column=\"fr_translate_10-shot\", score_column=\"10-shot-score\")\n",
    "\n",
    "print(\"1\")\n",
    "validation = evaluate_translations_td_idf(validation, model_column=\"fr_translate_base\", score_column=\"tdidf-base_score\")\n",
    "print(\"2\")\n",
    "validation = evaluate_translations_td_idf(validation, model_column=\"fr_translate_5-shot\", score_column=\"tdidf-5-shot-score\")\n",
    "print(\"3\")\n",
    "validation = evaluate_translations_td_idf(validation, model_column=\"fr_translate_10-shot\", score_column=\"tdidf-10-shot-score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0055ac5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ver = \"tdidf-\"\n",
    "validation[validation[f\"{score_ver}base_score\"] != 0][f\"{score_ver}base_score\"].mean(),\\\n",
    "validation[validation[f\"{score_ver}base_score\"] != 0][f\"{score_ver}base_score\"].std(),\\\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] != 0][f\"{score_ver}5-shot-score\"].mean(),\\\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] != 0][f\"{score_ver}5-shot-score\"].std(),\\\n",
    "validation[validation[f\"{score_ver}10-shot-score\"] != 0][f\"{score_ver}10-shot-score\"].mean(),\\\n",
    "validation[validation[f\"{score_ver}10-shot-score\"] != 0][f\"{score_ver}10-shot-score\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e2029",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_ver = \"\"\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] <= 98][f\"{score_ver}base_score\"].mean(),\\\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] <= 98][f\"{score_ver}base_score\"].std(),\\\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] <= 98][f\"{score_ver}5-shot-score\"].mean(),\\\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] <= 98][f\"{score_ver}5-shot-score\"].std(),\\\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] <= 98][f\"{score_ver}10-shot-score\"].mean(),\\\n",
    "validation[validation[f\"{score_ver}5-shot-score\"] <= 98][f\"{score_ver}10-shot-score\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c180c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def get_vecstore_similarity(english_title, model, k_neighbors=5):\n",
    "    results = vec_store.similarity_search(query=english_title, k=k_neighbors)\n",
    "    samples = [doc.metadata['en_title'] for doc in results]\n",
    "    embeddings = np.array(model.encode(samples, batch_size=k_neighbors, show_progress_bar=True).tolist()).reshape(k_neighbors, 1, -1)\n",
    "    embedding0 = np.array(model.encode([english_title], batch_size=k_neighbors, show_progress_bar=True).tolist()[0]).reshape(1, -1)\n",
    "    similarities = pd.Series([cosine_similarity(embedding0, embedding)[0][0] for embedding in embeddings]).astype(float)\n",
    "    return similarities.mean(), similarities.max(), similarities.min() \n",
    "\n",
    "# TODO: try other model embeddings (eg. document embeddings)\n",
    "validation[['5-shot-sim-mean', '5-shot-sim-max', '5-shot-sim-min']] = validation['en_title'].apply(lambda title: pd.Series(get_vecstore_similarity(title, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c94d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "\n",
    "# Create a dataframe\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Define variables for the plotting\n",
    "df['Max DB Cosine Similarity'] = (validation[(validation['5-shot-sim-max'] < 0.99)]['5-shot-sim-max'] * 100)\n",
    "df['Translation Score'] = (validation[(validation['5-shot-sim-max'] < 0.99)]['5-shot-score'])\n",
    "\n",
    "# Perform OLS regression to get the p-value\n",
    "X = sm.add_constant(df['Max DB Cosine Similarity'])  # Adds intercept term\n",
    "model = sm.OLS(df['Translation Score'], X).fit()\n",
    "p_value = model.pvalues['Max DB Cosine Similarity']\n",
    "\n",
    "# Display the scatter plot with trendline\n",
    "fig = px.scatter(\n",
    "    df,\n",
    "    x='Max DB Cosine Similarity',\n",
    "    y='Translation Score',\n",
    "    title=f'Translation Score vs. Database Example Similarity (p-value: {p_value:.3e})',\n",
    "    height=650,\n",
    "    width=750,\n",
    "    trendline='ols',\n",
    "    trendline_color_override='red'\n",
    ")\n",
    "\n",
    "# Show the plot\n",
    "fig.show()\n",
    "\n",
    "print(\"P-value for the line of best fit: {}\".format(p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ede8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "\n",
    "pearsonr(df['x'], df['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f57a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from bert_score import score\n",
    "from rouge_score import rouge_scorer\n",
    "import torch\n",
    "import sacrebleu\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "gdata = pd.read_csv(r\"google_translate.csv\")\n",
    "\n",
    "validation_df = validation[[\"en_title\", \"fr_title\"]]\n",
    "r_scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "chrf = sacrebleu.CHRF()\n",
    "\n",
    "def validation_score_generate(validation, model_column, ref_column=\"fr_title\", score_column=\"score\", clean_output = lambda x: x):\n",
    "    _, _, F1_base = score(validation[model_column].apply(clean_output).tolist(), validation[ref_column].tolist(), lang=\"fr\", device=device)\n",
    "    c_scores_base = [chrf.sentence_score(translated, [ref]).score \n",
    "                 for translated, ref in zip(validation[model_column].apply(clean_output), validation[ref_column])]\n",
    "    rouge_scores_base = [r_scorer.score(ref, hyp)['rougeL'].fmeasure*100\n",
    "                     for ref, hyp in zip(validation[ref_column], validation[model_column].apply(clean_output))]\n",
    "    validation[score_column] = [0.2*c + 0.3*f*100 + 0.5*r\n",
    "                            for c, f, r in zip(c_scores_base, F1_base, rouge_scores_base)]\n",
    "    print(c_scores_base[0])\n",
    "    return validation\n",
    "\n",
    "gdata = validation_score_generate(gdata, \"fr_google_translate\")\n",
    "gdata[\"score\"].astype(int).mean() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "translate_DS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
