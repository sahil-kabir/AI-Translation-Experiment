# AI Translation Experiment

🔒 Note: Due to proprietary restrictions, exact details of subject matter cannot be shared. This repo provides partially redacted/cleaned notebooks with visuals on technical details, and model performance.

🚀 Methods Explored
1. 🏗️ Retrieval-Augmented Generation (RAG + Closed-Source Models)

 - Text embeddings: (BERT + LangChain)
 - Zero-shot, and few-shot prompting using proprietary APIs
 - Multi-shot prompt injection with retrieval from a vector database (RAG-lite)

2. 🧠 Fine-Tuning (Open-Source Models)

 - Model: Helsinki-NLP Opus MT
 - Fine-tuning on parallel corpora with PEFT and LoRA techniques
 - Grid search over hyperparameters with structured evaluation

