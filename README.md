# AI Translation Experiment

ğŸ”’ Note: Due to proprietary restrictions, exact details of subject matter cannot be shared. This repo provides partially redacted/cleaned notebooks with visuals on technical details, and model performance.

ğŸš€ Methods Explored
1. ğŸ—ï¸ Retrieval-Augmented Generation (RAG + Closed-Source Models)

 - Text embeddings: (BERT + LangChain)
 - Zero-shot, and few-shot prompting using proprietary APIs
 - Multi-shot prompt injection with retrieval from a vector database (RAG-lite)

2. ğŸ§  Fine-Tuning (Open-Source Models)

 - Model: Helsinki-NLP Opus MT
 - Fine-tuning on parallel corpora with PEFT and LoRA techniques
 - Grid search over hyperparameters with structured evaluation

